# Explaining Reinforcement Learning with Shapley Values | Tutorial

## Outline

- [Introduction](#introduction)
- [Explainable Artificial Intelligence](#explainable-artificial-intelligence)
- [Shapley values](#shapley-values)
- [Environment](#environment)
- [Shapley values applied to policy](#shapley-values-applied-to-policy)
- [SVERL-P](#sverl-p)
- [Demo](#demo)
- [Conclusion](#conclusion)
- [References](#references)

# Introduction

TODO: RL image



# Explainable Artificial Intelligence

TODO

# Shapley values

TODO

# Environment

# Shapley values applied to policy

# SVERL-P

# Demo

# Conclusion

# References

- [1] [Beechey et. al. “Explaining Reinforcement Learning with Shapley Values”](https://proceedings.mlr.press/v202/beechey23a/beechey23a.pdf)
- [2] [OpenAI Hide-and-Seek simulation](https://www.youtube.com/watch?v=kopoLzvh5jY)
- [3] [Trends in Explainable AI by Alon Jacovi](https://arxiv.org/pdf/2301.05433)
- [3] Rustam Lukmanov, Explainable and Fair AI, Spring 24, Lecture 1
- [4] [The mathematics behind Shapley Values](https://www.youtube.com/watch?v=UJeu29wq7d0)
- [5] [Shapley values](https://en.wikipedia.org/wiki/Shapley_value#Properties)
- [6] [Geng game engine](https://github.com/geng-engine/geng)
- [7] [Our implementation with environment in Rust](https://github.com/1ADIS1/xai-sverl)
